{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build-a-bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hlab-repo/learning/blob/main/Build_a_Text_Bot_by_Timothy_Beal_and_Michael_Hemenway.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN4Ehli4Dqzc"
      },
      "source": [
        "# **BUILD A TEXT BOT**\n",
        "\n",
        "**by Timothy Beal and Michael Hemenway, [h.lab](https://case.edu/artsci/hlab/)**\n",
        "\n",
        "Build a fully functional text bot in the programming language of Python. No coding experience necessary, but each step is annotated for those who want to understand more about what's going on from line to line.\n",
        "\n",
        "This is a slightly simplified version of the program behind [KJVBot](https://twitter.com/kjvbot), which autogenerates and then tweets its own verses based on the King James Version Bible. Many thanks to Justin Barber for extensive help in desiging and building the original Markov bot.\n",
        "\n",
        "Once you work your way though this notebook, you can easily adapt it to work from other texts (see the simple instructions at the end).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n09eYwDNv8aR"
      },
      "source": [
        "##**About Markov Processes**\n",
        "\n",
        "This bot uses something called a Markov chain. Named after the Russian mathematicial Andrey Andreyevich Markov (1856–1922), a Markov chain is a simple yet powerful process of prediction. It begins with a *current state* and predicts (based on training data) what the *next state* to follow that state will be.\n",
        "\n",
        "Let's say, for example, we are trying to predict the weather. Today, which is our current state, is rain. First, we build a list of every next state, or next day's weather, that has followed rain. Imagine that list, which is the Markov chain's training data, looks like this: `(cloudy, rain, cloudy, sunny, rain, rain, rain, rain, rain, rain)`. The Markov process then randomly chooses from that list, and whatever it chooses becomes the new current state. Given that `rain` is followed by more `rain` seven out of ten times (70 percent) in our list, more `rain` is quite probable. Still, `cloudy` has a 20 percent chance and `sunny` has a 10 percent chance. And so on.\n",
        "\n",
        "But how this process work for a text bot? Imagine that our database is not weather history but *The New York Times*, and that our current state is the word \"Barack\". Our program would go through the entire database of news text (very quickly!), making a list of every next state, that is, next word or punctuation mark, that has ever followed \"Barack\" in the *Times*. Then it would randomly select one from that list. Let's say that, of the millions of occurences of \"Barack,\" the word \"Obama\" is the next state that follows \"Barack\" 90 percent of the time. Roughly nine times out of ten, then, the program will end up randomly selecting that word as its next state. \"Obama\" then becomes the current state, and the process begins again, compiling and selecting from a list of all its next states. And so on, and so on, adding each next state to the utterance until it reaches a predetermined stopping point (e.g., a period or a maximum number of words).\n",
        "\n",
        "This bot works in a similar way, continuing the process until it lands upon a period, exclamation mark, or question mark, at which point it stops. If the length of the resulting utterance is less than 130 characters (or whatever you set the limit to be), it prints (i.e., displays) that utterance. If it's over the set limit, it starts again from scratch. And so on.\n",
        "\n",
        "Don't worry if the process is not entirely clear to you yet. Working through the following steps should help. So let's dive in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vUQwt_ZwLKy"
      },
      "source": [
        "##**1. Save a Copy of This Notebook**\n",
        "\n",
        "First, you need to make a copy of this Colab notebook that you can edit and run it yourself. Go to “File” / “Save a copy in Drive” and save it to your own Google Drive space (or use the GitHub option if you prefer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMzsFCizwm5B"
      },
      "source": [
        "##**2. Download the KJV Bible**\n",
        "\n",
        "Next, open this KJV Bible text file and save it to your own computer: https://drive.google.com/file/d/1A9aiYV3XvsfoC81M7jgPimu1m4wFA7Ww/view. Important: remember where you saved it.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOfelDXFXK7"
      },
      "source": [
        "##**3. Import the Needed Libraries**\n",
        "\n",
        "Libraries are collections of pre-written code that you can import in order to carry out certain actions more efficiently. In case you are interested, these are the libaries we will import and use:\n",
        "\n",
        "> **`files`** (part of Google's larger **colab** library, thus imported \"`from google.colab`\"), which allows us to upload the text file from Drive or a local computer into this program;\n",
        "\n",
        "> **`nltk`** (\"Natural Language Tool Kit\" library), which we use to convert our text from a single string of words and punctuation into a list of sentences;\n",
        "\n",
        "> **`tee`** (part of the **`itertools`** library), which makes a list of sequences, with each sequence moving ahead one step (see below in the `list_crawler` function);\n",
        "\n",
        "> **`defaultdict`** (part of the **`collections`** library), which works with **`tee`** to make a dictionary (a collection of key:value pairs) that will give us every next word (*next state*) that follows every three-word string (*current state*) in our text;\n",
        "\n",
        "> **`re`** is the **`regular expressions`** library, which we use to clean up and prepare the text; and\n",
        "\n",
        "> **`choice`** (part of the **`random`** library), which randomly chooses an item from a list (we use it to randomly choose the bot's starting point from a list of possible starting phrases).\n",
        "\n",
        "The next cell is our first block of code, which will import all of the above into our program. *To run it, click the play button in the upper left corner.*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of5rjES_FqiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4273200-d262-4f91-9368-46144da93075"
      },
      "source": [
        "from google.colab import files\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from itertools import tee\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from random import choice\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu9-lpZvM7zq"
      },
      "source": [
        "##**4. Upload your Text File**\n",
        "\n",
        "In Colab, you need to upload any text or other files your program uses every time you start a new session. Here we will upload a plain text version of the King James Version Bible.\n",
        "\n",
        "Run the next cell to prepare Colab to upload or \"mount\" the text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTqAGTNEDQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eed34bd-e663-4970-83b6-df7087917457"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpimH2Mc4IoV"
      },
      "source": [
        "Now run this cell and a pop up menu will appear. Find your kjv.txt file wherever you saved it. Colab will upload it for use during this session.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me7RG5C4M5mv",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5f6d2b90-3073-4347-9d30-f4d9ec192e09"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d88f3661-8d43-4c27-b7a4-e4248901dc59\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d88f3661-8d43-4c27-b7a4-e4248901dc59\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kjv.txt to kjv.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvnuCA5UP6H4"
      },
      "source": [
        "##**5. Define the Three Functions Needed to Run the Bot.**\n",
        "\n",
        "A function is a block of code with a name that runs when it is \"called\" (i.e., named) later in the program. Often, functions are called within other functions. Here we define the three functions that this bot will use: `list_crawler()`, `build_sentence()`, and `markovize()`. Later in the program, you'll see that the first two functions, `list_crawler()` and `build_sentence()`, will actually be called *within* the third function, `markovize()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYJZTVcWQfQ-"
      },
      "source": [
        "**A. Define the `list_crawler()` function.**\n",
        "\n",
        "These lines build a function that crawls through a list -- in this case, the KJV text as a list of words and punctuation marks -- moving forward one step each time. So, if our text were Genesis 1, it would result in a list like this: `[(\"in\", \"the\", \"beginning\"), (\"the\", \"beginning\", \"god\"), (\"beginning\", \"god\", \"created\"), (\"god\", \"created\", \"the\")]`. This function will be used called within the `markovize()` function to find all *next states* for all *current states* (see below).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-QQijaery3A"
      },
      "source": [
        "def list_crawler(iterable, n=2):\n",
        "    if len(iterable) < n:\n",
        "        return\n",
        "    iterables = tee(iterable, n)\n",
        "    for i, iter_ in enumerate(iterables):\n",
        "        for num in range(i):\n",
        "            next(iter_)\n",
        "    return zip(*iterables)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUv-N-_f-Iw"
      },
      "source": [
        "**B. Define the `build_sentence()` function.**\n",
        "\n",
        "These lines will be used along with `list_crawler()` inside the `markovize()` function, below, to create the new utterance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39j3uRw1udHm"
      },
      "source": [
        "def build_sentence(seed, sent_tokens):\n",
        "    token = ''\n",
        "    while token not in set('׃.?!\\n'):\n",
        "        last_tokens = tuple(seed[-3:])\n",
        "        new_token = choice(sent_tokens[last_tokens])\n",
        "        seed.append(new_token)\n",
        "        token = new_token\n",
        "    sentence = ' '.join(seed)\n",
        "    sentence = re.sub(r'\\s+([׃.,?!:;\\n])', r'\\1', sentence)\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8AphkZAs_Ur"
      },
      "source": [
        "**C. Define the `markovize()` function.**\n",
        "\n",
        "This function does a lot. First, it opens the text we uploaded (lines 2-3). Then it turns that text into a list of separated sentences (line 4) and tokens (i.e., words and punctuation marks; lines 6-7). Then, using the `list_crawler()` function, defined above, and the `defaultdict` library that we imported, it turns that list of tokens into a huge dictionary of key:value pairs, with each \"key\" being a three-token string and each \"value\" being the next word that follows that string in the text. What this gives us, then, is every next word, or *next state*, that comes after every three-word phrase, or *current state*, in the text. The result of this process gives us a very, very long dictionary that looks like this (with the three tokens in parentheses as the key and the bracketed token, which is the *next state* in the text, as the value for that key):\n",
        "\n",
        ">`{('the', 'revelation', 'of'): ['jesus'], ('revelation', 'of', 'jesus'): ['christ'], ('of', 'jesus', 'christ'): [','], ('jesus', 'christ', ','): ['which'], ('christ', ',', 'which'): ['god'], (',', 'which', 'god'): ['gave'] ...}`\n",
        "\n",
        "Once it has built that dictionary, the `build_sentence()` function works within an iterating loop to build the actual verse or \"utterance.\" It does so using a Markov process: beginning with a three-token start phrase as its *current state*, it makes a list of all possible *next states* (tokens that follow that phrase) in the text, and then randomly selects one from its list. That new token then becomes the third of the three tokens in the *current state* (the former first token drops off), and the process begins again. The process continues until it randomly selects a period, exclamation point, or question mark, at which point it stops. If the resulting utterance is less than 130 characters (or whatever you set the limit to be), it prints it; if not, it starts all over again with a new three-token start phrase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MabOs0O5gPsZ"
      },
      "source": [
        "def markovize(word1, word2, word3, fileid, char_limit=None):\n",
        "    with open(fileid, encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    sentences = sent_tokenize(text)\n",
        "    sent_tokens = defaultdict(list)\n",
        "    for sentence in sentences:\n",
        "        tokens = re.findall(r\"[\\w']+|[׃.,?!:;\\n]\", sentence)\n",
        "        crawled_list = list_crawler(tokens, n=4)\n",
        "        if crawled_list:\n",
        "            for token1, token2, token3, token4 in crawled_list:\n",
        "                sent_tokens[token1, token2, token3].append(token4)\n",
        "    too_long = True\n",
        "    while too_long:\n",
        "        sentence = [word1, word2, word3]\n",
        "        utterance = build_sentence(sentence, sent_tokens)\n",
        "        len_utterance = len(utterance)\n",
        "        if char_limit is not None and len_utterance > char_limit:\n",
        "            too_long = True\n",
        "        else:\n",
        "            too_long = False\n",
        "    print(utterance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzPBK2vynSE"
      },
      "source": [
        "##**6. Create Different Start Phrases for the Bot**\n",
        "\n",
        "Here we simply create a list of possible three-token starting points for the bot. Note that they all need to show up someplace in the KJV text or the bot will fail before it begins. We use the **`choice`** library that we imported to randomly choose the starting point for the bot each time it runs.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ73FjwuzLA3"
      },
      "source": [
        "start_phrases = [[\"Woe\", \"unto\", \"the\"],\n",
        "     [\"And\", \"when\", \"he\"],\n",
        "     [\"And\", \"I\", \"saw\"],\n",
        "     [\"And\", \"he\", \"answered\"],\n",
        "     [\"And\", \"the\", \"priest\"],\n",
        "     [\"In\", \"the\", \"beginning\"]]\n",
        "\n",
        "[word1, word2, word3] = choice(start_phrases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJcY4m5nzmhT"
      },
      "source": [
        "##**7. Run the Bot!**\n",
        "\n",
        "We run the bot by calling the function `markovize()`, which, as we saw, incorporates the two previous functions within it. We do that simply by typing its name along with the \"arguments\" (placed inside the parenthesis) it needs to run. These arguments are: the first three tokens (`word1, word2, word3`, which have been randomly selected from the five choices for \"start_phrases\", above), the text file it will process (`kjv.txt`), and the character limit for the utterance (`130`).\n",
        "\n",
        "After you've run the whole program once during a session, you can simply run the last two cells to produce new utterances with new start phrases (or run only the last cell to rerun the bot with the same start phrase).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jZDoZ5q090U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12e3323-30a9-418e-e1f4-55457c6bc22f"
      },
      "source": [
        "markovize(word1, word2, word3, \"kjv.txt\", 130)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the beginning of our confidence stedfast unto the end of heaven to the other.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2uZPTLr2ZR1"
      },
      "source": [
        "##**Things to Try Next**\n",
        "\n",
        "1. Experiment with longer or shorter length limits for by changing `130` to a different number.\n",
        "2. Change some or all of the start phrases in the previous cell to ones you know are in the KJV text.\n",
        "3. Adapt this program to work with a different text by (a) uploading a different plain text file (include a space before and after each punctuation mark so the program recognizes it as a separate token), (b) replacing \"kjv.txt\" with your file name, and (c) change the start phrases to ones you know are in that text.\n",
        "4. See if you can revise the program so that it uses a shorter or longer start phrase. How does that change the kinds of utterances it produces?\n",
        "\n",
        "The last two will take a little more time, but they could be fun ways to learning some coding by diving in!\n"
      ]
    }
  ]
}