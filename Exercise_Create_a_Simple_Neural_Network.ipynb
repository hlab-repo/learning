{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise: Create a Simple Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvQo5HhmdmPD"
      },
      "source": [
        "# Constructing a Simple Neural Network with PyTorch\n",
        "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwvOXx-NDpWj"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDhHrwMCypMQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjJIfukKDtTt"
      },
      "source": [
        "## Get Train and Test Datasets\n",
        "\n",
        "All torchvision datasets are subclasses of `torch.utils.data.Dataset`. Hence, they can all be passed to a `torch.utils.data.DataLoader` which can load multiple samples in parallell using torch.multiprocessing workers.\n",
        "\n",
        "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk3amRQOzS6m"
      },
      "source": [
        "%%capture\n",
        "mnist_train = datasets.MNIST('mnist', download=True, transform=transforms.PILToTensor(), train=True)\n",
        "mnist_test = datasets.MNIST('mnist', download=True, transform=transforms.PILToTensor(), train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s76WlRKkzwfD"
      },
      "source": [
        "mnist_train[0][0], mnist_train[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYQejbIy560y"
      },
      "source": [
        "transforms.functional.to_pil_image(mnist_train[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkLn6PrHD0mi"
      },
      "source": [
        "## Create Neural Network Model with `nn.Sequential`\n",
        "\n",
        "A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.\n",
        "\n",
        "To make it easier to understand, here is a small example:\n",
        "\n",
        "```\n",
        "# Example of using Sequential\n",
        "model = nn.Sequential(\n",
        "          nn.Linear(32, 16),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(16, 1),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "# Example of using Sequential with OrderedDict\n",
        "model = nn.Sequential(OrderedDict([\n",
        "          ('linear1', nn.Linear(32, 16)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('linear2', nn.Linear(16, 1)),\n",
        "          ('relu2', nn.ReLU())\n",
        "        ]))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TmDesfQiqOv"
      },
      "source": [
        "As an aside, note that `nn.Linear` applies a linear transformation to the incoming data: $y = xA^T + b$. ($xA^T$ represents a dot product.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyzxbOGtiUW4"
      },
      "source": [
        "m = nn.Linear(5, 10)\n",
        "input_ = torch.randn(32, 5)  # batch size == 32; number of features for each sample == 5\n",
        "output = m(input_)\n",
        "output.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vUV3Yg8QUtU"
      },
      "source": [
        "Create *your own model* for the **MNIST** datatset here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOjZ8Dj70DYy"
      },
      "source": [
        "seq_model = nn.Sequential(\n",
        "    # TODO: Add one or more nn.Linear layer arguments each followed by a\n",
        "    # non-linearity (such as nn.ReLU). Your first `nn.Linear` layer should\n",
        "    # accept 28 * 28 input features. Your final `nn.Linear` layer should \n",
        "    # have 10 output features (one for each number) and be followed by\n",
        "    # `nn.Softmax(dim=-1)`, which will convert the `nn.Linear` outputs to\n",
        "    # probabilities. (~4 lines of code or more)\n",
        "    \n",
        ").cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r1kdh3t0-3R"
      },
      "source": [
        "seq_model  # what does your model look like?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT3tIFuxQNsV"
      },
      "source": [
        "Test your linear model on a flattened image to make sure all shapes are correct:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esSRvGvK04ZJ"
      },
      "source": [
        "flattened_tensor = mnist_train[0][0].view(1, 1, -1) / 256.\n",
        "seq_model(flattened_tensor.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSq0vG9VWRTn"
      },
      "source": [
        "## Create More Flexible Neural Network Models with `nn.Module`\n",
        "\n",
        "`nn.Module` is the base class for all neural network modules. Your models should subclass this class. Modules can contain other Modules, allowing nesting in a tree structure. You can assign the submodules as regular instance attributes:\n",
        "\n",
        "```\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.relu(self.conv2(x))\n",
        "```\n",
        "\n",
        "Submodules assigned in this way will be registered and will have their parameters included in the top-level Module's parameters. For example:\n",
        "\n",
        "```\n",
        ">>> model = Model()\n",
        ">>> for name, param in model.named_parameters():\n",
        "    print(name, '=>', param.shape)\n",
        "conv1.weight => torch.Size([20, 1, 5, 5])   # a model.conv1 parameter\n",
        "conv1.bias => torch.Size([20])              # another model.conv1 parameter\n",
        "conv2.weight => torch.Size([20, 20, 5, 5])  # a model.conv2 parameter\n",
        "conv2.bias => torch.Size([20])              # another model.conv2 parameter\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO1Tj04LaND3"
      },
      "source": [
        "*Now can you replicate the `seq_model` model you created above with `nn.Module`?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVBt55Q9boeE"
      },
      "source": [
        "seq_model  # show again what the `seq_model` looks like for replication"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxtxjL_6aLuA"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor, you declare all the layers you want to use.\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        # TODO: Add linear layers to instance attributes here (~2 lines or more)\n",
        "\n",
        " \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function, you define how your model is going to be run,\n",
        "        from input to output. This method is run automatically when the instance\n",
        "        is called.\n",
        "        \"\"\"\n",
        "        # TODO: Use the linear layer (and other) attributes assigned above to \n",
        "        # calculate the `outputs`. (~4 lines)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8L3dPQnb5_m"
      },
      "source": [
        "m_model = Model().cuda()\n",
        "m_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H1kYdsnD--M"
      },
      "source": [
        "## Create Loss Function, Optimizer, and DataLoader\n",
        "\n",
        "**Criterion**: `nn.CrossEntropyLoss` is useful when training a classification problem with C classes. The *input* is expected to contain raw scores *for each class*. This criterion expects *a class index* in the range [0, C-1] as the *target* for each value of a 1D tensor of size minibatch.\n",
        "\n",
        "**Optimizer**: `torch.optim` implements various optimization algorithms. To use `torch.optim`, you have to construct an optimizer object, which will hold the current state and will update the parameters based on the computed gradients. To construct an Optimizer you have to give it an iterable containing the parameters to optimize. You can also specify learning rate, weight decay, etc. We will use `optim.Adam` here, a good default.\n",
        "\n",
        "**DataLoader**: At the heart of PyTorch data loading utility is the `torch.utils.data.DataLoader` class. It represents a Python iterable over a dataset. A DataLoader performs automatic batching. The DataLoader fetches a minibatch of data and collates them into batched samples. It generates Tensors with one dimension being the batch dimension (usually the first dimension)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ySDjF7n16Il"
      },
      "source": [
        "criterion = # TODO: enter the loss function here (`nn.CrossEntropyLoss`).\n",
        "optimizer = # TODO: enter the optimizer here (`optim.Adam`, learning rate of 1e-3).\n",
        "dataloader = # TODO: enter the `DataLoader` here (with batch size 128 or so)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hoxn3shQEEvi"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "Here is where our network organizes and optimizes itself. We simply have to loop over our data iterator, feed the inputs to the network, and optimize the network's weights (parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIhHcqar27_b"
      },
      "source": [
        "def train(model, criterion, optimizer, dataloader, epochs=30, flatten=True):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        running_loss = 0.\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X = X.cuda() / 256.\n",
        "            if flatten:\n",
        "                X = X.view(X.shape[0], -1)  # flatten the images\n",
        "            y = y.cuda()\n",
        "\n",
        "            # TODO: Get the outputs of the model and assign them to the name `outputs`,\n",
        "            # and then get the loss of the model using `criterion` and assign it the \n",
        "            # name `loss`. (2 lines of code)\n",
        "            \n",
        "\n",
        "            running_loss += loss\n",
        "\n",
        "            # TODO: Use `zero_grad` to zero the gradient of the optimizer. Then\n",
        "            # calculate the gradients using the `backward` method of loss, and\n",
        "            # finally have the optimizer take a step. (3 lines of code)\n",
        "            \n",
        "\n",
        "            print('Epoch: {} Batch: {} Loss: {} Running Loss: {}'\n",
        "                  .format(epoch, batch, loss, running_loss / (batch + 1)))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0vSbUyuUfwO"
      },
      "source": [
        "Now train our model by calling the `train` function. Feel free to use your `m_model` or your `seq_model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm4yt25nEdeQ"
      },
      "source": [
        "model = train(m_model, criterion, optimizer, dataloader, epochs=10, flatten=True)\n",
        "# model = train(seq_model, criterion, optimizer, dataloader, epochs=10, flatten=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ys7TJ0bAC-d"
      },
      "source": [
        "## Check the Model's Performance on Each Class\n",
        "\n",
        "A confusion matrix is a specific table layout that allows visualization of the performance of an algorithm. Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBWRfFgp5HsJ"
      },
      "source": [
        "def generate_confusion_matrix(model, dataloader, num_classes=10, flatten=True):\n",
        "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X = X.cuda() / 256.\n",
        "            if flatten:\n",
        "                X = X.view(X.shape[0], -1)  # flatten the images\n",
        "            y = y.cuda()\n",
        "\n",
        "            outputs = model(X)\n",
        "            \n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "            for t, p in zip(y.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    return pd.DataFrame(confusion_matrix.numpy(), columns=range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Rhel-m_AwN"
      },
      "source": [
        "# get dataloader for the test set, which the model has never seen before\n",
        "test_dataloader = DataLoader(mnist_test, batch_size=128)\n",
        "# now generate confusion matrix\n",
        "results = generate_confusion_matrix(seq_model, test_dataloader, num_classes=10)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAYpPUCiVDp9"
      },
      "source": [
        "Now check the accuracy for each class label (we could use f1 score etc. as well):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOVrnlel83Ia"
      },
      "source": [
        "print(np.diag(results.values) / results.sum(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2spFGGyVQnl"
      },
      "source": [
        "And finally check the overall accuracy score when each class is equally weighted:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnfSqwHq-tBD"
      },
      "source": [
        "print((np.diag(results) / results.sum()).mean())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}